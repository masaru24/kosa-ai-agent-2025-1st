{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent # 가장 높은 수준의 추상화된 agent. AssistantAgent와 UserProxyAgent가 모두 이 agent를 상속\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's one for you:\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "Because they don't have the guts!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why don’t skeletons fight each other? \n",
      "\n",
      "Because they don’t have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a classic, Cathy! You know what they say about skeletons — they really know how to rattle a crowd! Want to hear one from me? How about this: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "That's a good one, Joe! I guess you could say he really stood out! Okay, here's another for you: Why did the bicycle fall over? Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why don’t skeletons fight each other? \n",
      "\n",
      "Because they don’t have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a classic, Cathy! You know what they say about skeletons — they really know how to rattle a crowd! Want to hear one from me? How about this: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "That's a good one, Joe! I guess you could say he really stood out! Okay, here's another for you: Why did the bicycle fall over? Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why don’t skeletons fight each other? \n",
      "\n",
      "Because they don’t have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a classic, Cathy! You know what they say about skeletons — they really know how to rattle a crowd! Want to hear one from me? How about this: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "That's a good one, Joe! I guess you could say he really stood out! Okay, here's another for you: Why did the bicycle fall over? Because it was two-tired!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, that's a great pun, Cathy! You really know how to pedal those jokes! Speaking of tired, how about this: Why don’t scientists trust atoms? Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "That’s a classic, Joe! Atoms really are the building blocks of a good joke! Here’s one that’s a bit cheesy: What do you call cheese that isn’t yours? Nacho cheese!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(\n",
    "    cathy, message=\"Cathy, tell me a joke.\", max_turns=3\n",
    ")  # increase the number of max turns before termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why don’t skeletons fight each other? \n",
      "\n",
      "Because they don’t have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That’s a classic, Cathy! Here’s one for you: Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "That's a good one, Joe! You know, I’ve always thought scarecrows had a great work ethic—it’s just too bad they can’t get promoted. They’re stuck in a field job!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    max_consecutive_auto_reply=1,  # Limit the number of consecutive auto-replies.\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke and then say the words GOOD BYE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here you go! \n",
      "\n",
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "GOOD BYE!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke and then say the words GOOD BYE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatResult(chat_id=None, chat_history=[{'content': 'Cathy, tell me a joke and then say the words GOOD BYE.', 'role': 'assistant', 'name': 'joe'}, {'content': 'Sure, here you go! \\n\\nWhy did the scarecrow win an award? \\n\\nBecause he was outstanding in his field!\\n\\nGOOD BYE!', 'role': 'user', 'name': 'cathy'}], summary='Sure, here you go! \\n\\nWhy did the scarecrow win an award? \\n\\nBecause he was outstanding in his field!\\n\\nGOOD BYE!', cost={'usage_including_cached_inference': {'total_cost': 0.00026385, 'gpt-4o-mini-2024-07-18': {'cost': 0.00026385, 'prompt_tokens': 711, 'completion_tokens': 262, 'total_tokens': 973}}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke and then say the words GOOD BYE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here you go! \n",
      "\n",
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "GOOD BYE!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ChatResult(chat_id=None, chat_history=[{'content': 'Cathy, tell me a joke and then say the words GOOD BYE.', 'role': 'assistant', 'name': 'joe'}, {'content': 'Sure, here you go! \\n\\nWhy did the scarecrow win an award? \\n\\nBecause he was outstanding in his field!\\n\\nGOOD BYE!', 'role': 'user', 'name': 'cathy'}], summary='Sure, here you go! \\n\\nWhy did the scarecrow win an award? \\n\\nBecause he was outstanding in his field!\\n\\nGOOD BYE!', cost={'usage_including_cached_inference': {'total_cost': 0.00028845, 'gpt-4o-mini-2024-07-18': {'cost': 0.00028845, 'prompt_tokens': 755, 'completion_tokens': 292, 'total_tokens': 1047}}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['exit'])\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": os.environ.get(\"OPENAI_DEFAULT_MODEL\"), \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"ALWAYS\",  # NEVER, ALWAYS, TERMINATE\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke and then say the words GOOD BYE.\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
